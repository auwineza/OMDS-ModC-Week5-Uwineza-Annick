{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e3418e",
   "metadata": {},
   "source": [
    "# Week 5 â€” Support Vector Machines (CKD Capstone)\n",
    "**Dataset:** `/mnt/data/Chronic_Kidney_Dsease_data.csv`  \n",
    "**Target:** `Diagnosis` (binary)  \n",
    "**Notes:** Drops identifier columns `['PatientID', 'DoctorInCharge']` if present; imputes missing values; handles categoricals with one-hot; uses class weighting for imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4d05d",
   "metadata": {},
   "source": [
    "## 0) Setup & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b43d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7,4)\n",
    "np.random.seed(42)\n",
    "print('Libraries imported OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d9c7f8",
   "metadata": {},
   "source": [
    "## 1) Load CKD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/mnt/data/Chronic_Kidney_Dsease_data.csv\"\n",
    "TARGET_COL = \"Diagnosis\"\n",
    "ID_COLS = ['PatientID', 'DoctorInCharge']\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea8ca7",
   "metadata": {},
   "source": [
    "## 2) Train/test split and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop IDs if present\n",
    "df = df.drop(columns=[c for c in ID_COLS if c in df.columns])\n",
    "\n",
    "# Features / target\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Numeric vs categorical\n",
    "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "print(f'Numeric: {len(num_cols)} | Categorical: {len(cat_cols)}')\n",
    "\n",
    "# Split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Pipelines\n",
    "numeric_tf = Pipeline([('imputer', SimpleImputer(strategy='median')), \n",
    "                       ('scaler', StandardScaler())])\n",
    "categorical_tf = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "                           ('oh', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [('num', numeric_tf, num_cols), ('cat', categorical_tf, cat_cols)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2261d3",
   "metadata": {},
   "source": [
    "## 3) Baselines: Linear vs RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30041213",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"linear\": Pipeline([('prep', preprocess),\n",
    "                        ('svm', SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42))]),\n",
    "    \"rbf\":    Pipeline([('prep', preprocess),\n",
    "                        ('svm', SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42))]),\n",
    "    \"poly\":   Pipeline([('prep', preprocess),\n",
    "                        ('svm', SVC(kernel='poly', degree=3, class_weight='balanced', probability=True, random_state=42))]),\n",
    "}\n",
    "rows = []\n",
    "for name, m in models.items():\n",
    "    m.fit(X_train, y_train)\n",
    "    y_pred = m.predict(X_test)\n",
    "    y_prob = m.predict_proba(X_test)[:,1]\n",
    "    rows.append({\n",
    "        'kernel': name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob)\n",
    "    })\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46eda87",
   "metadata": {},
   "source": [
    "## 4) 5-fold CV comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "def cv_kernel(name, est):\n",
    "    pipe = Pipeline([('prep', preprocess), ('svm', est)])\n",
    "    scores = cross_validate(pipe, X, y, cv=cv, scoring=['accuracy','f1','roc_auc'])\n",
    "    return {'kernel': name,\n",
    "            'acc_cv': scores['test_accuracy'].mean(),\n",
    "            'f1_cv': scores['test_f1'].mean(),\n",
    "            'auc_cv': scores['test_roc_auc'].mean()}\n",
    "\n",
    "cv_rows = []\n",
    "for name, est in {\n",
    "    'linear': SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42),\n",
    "    'rbf':    SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42),\n",
    "    'poly':   SVC(kernel='poly', degree=3, class_weight='balanced', probability=True, random_state=42)\n",
    "}.items():\n",
    "    cv_rows.append(cv_kernel(name, est))\n",
    "cv_df = pd.DataFrame(cv_rows); cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894dc0f",
   "metadata": {},
   "source": [
    "## 5) Regularization sweeps: C and gamma (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61dbb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_param(param, values):\n",
    "    means = []\n",
    "    for v in values:\n",
    "        est = SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42)\n",
    "        pipe = Pipeline([('prep', preprocess), ('svm', est.set_params(**{param: v}))])\n",
    "        s = cross_validate(pipe, X, y, cv=cv, scoring='roc_auc')['test_score'].mean()\n",
    "        means.append(s)\n",
    "    return means\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "C_vals = np.logspace(-2, 2, 8); gamma_vals = np.logspace(-3, 1, 9)\n",
    "\n",
    "auc_C = sweep_param('C', C_vals)\n",
    "plt.figure(); plt.plot(C_vals, auc_C, marker='o'); plt.xscale('log'); plt.xlabel('C'); plt.ylabel('CV ROC AUC'); plt.title('RBF: C sweep'); plt.show()\n",
    "\n",
    "auc_g = sweep_param('gamma', gamma_vals)\n",
    "plt.figure(); plt.plot(gamma_vals, auc_g, marker='o'); plt.xscale('log'); plt.xlabel('gamma'); plt.ylabel('CV ROC AUC'); plt.title('RBF: gamma sweep'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cca8b4",
   "metadata": {},
   "source": [
    "## 6) GridSearchCV on RBF/Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'svm__kernel': ['rbf','poly'],\n",
    "    'svm__C': np.logspace(-2, 2, 6),\n",
    "    'svm__gamma': ['scale'] + list(np.logspace(-3, 0, 4)),\n",
    "    'svm__degree': [2,3]\n",
    "}\n",
    "pipe = Pipeline([('prep', preprocess), ('svm', SVC(class_weight='balanced', probability=True, random_state=42))])\n",
    "gs = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params:', gs.best_params_)\n",
    "print('Best CV ROC AUC:', gs.best_score_)\n",
    "\n",
    "best = gs.best_estimator_\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "print(classification_report(y_test, best.predict(X_test)))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, best.predict(X_test)); plt.title('Confusion Matrix (Test)'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18692aa5",
   "metadata": {},
   "source": [
    "## 7) Notes: kernel trick & regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73c1de",
   "metadata": {},
   "source": [
    "SVMs achieve non-linear decision boundaries via a kernel that computes pairwise similarity without explicitly mapping features.  \n",
    "`C` controls regularization; larger `C` can overfit. For RBF and polynomial kernels, `gamma` (and `degree`) adjust complexity/scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320a14d",
   "metadata": {},
   "source": [
    "## 8) Conclusions (fill in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e5b4f",
   "metadata": {},
   "source": [
    "- Which kernel worked best on CKD?  \n",
    "- How did `C` and `gamma` affect performance?  \n",
    "- Class imbalance observations and next steps for Milestone One.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
